{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wLEuM_BQzm7U7RLX8Kzx\n"
     ]
    }
   ],
   "source": [
    "# get api key from your .env file\n",
    "import os\n",
    "from dotenv import load_dotenv  # if missing this module, simply run `pip install python-dotenv`\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasdaq Data has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Nasdaq Data API instructions here: https://docs.data.nasdaq.com/docs/in-depth-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Nasdaq API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Nasdaq API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "r = requests.get('https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json', params={'api_key': API_KEY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = r.json()['dataset_data']\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "print(dataset['column_names'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'api_key': API_KEY, 'start_date': '2017-01-01', 'end_date': '2017-12-25'}\n",
    "r = requests.get('https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n",
      "2017-01-01\n",
      "2017-12-25\n"
     ]
    }
   ],
   "source": [
    "dataset = r.json()['dataset_data']\n",
    "print(dataset['column_names'])\n",
    "print(dataset['start_date'])\n",
    "print(dataset['end_date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = dataset['data']\n",
    "column_names = dataset['column_names']\n",
    "\n",
    "data = []\n",
    "for row in data_list:\n",
    "  row_dict = {}\n",
    "  for index, key in enumerate(column_names):\n",
    "    row_dict[key] = row[index]\n",
    "  # excludes some rows with missing data\n",
    "  if(row_dict['Open']):\n",
    "    data.append(row_dict)\n",
    "\n",
    "# (is that helpful?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest opening price: $53.11\n",
      "lowest opening price: $34.00\n"
     ]
    }
   ],
   "source": [
    "max_opening_price = max(map(lambda row: row['Open'], data))\n",
    "print('highest opening price: ${:2.2f}'.format(max_opening_price))\n",
    "\n",
    "min_opening_price = min(map(lambda row: row['Open'], data))\n",
    "print('lowest opening price: ${:2.2f}'.format(min_opening_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What was the largest change in any one day(based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest change in one day: $2.81\n"
     ]
    }
   ],
   "source": [
    "max_day_change = max(map(lambda row: row['High'] - row['Low'], data))\n",
    "print('largest change in one day: ${:2.2f}'.format(max_day_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What was the largest change between any two days(based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest change between two consecutive days: $2.56\n"
     ]
    }
   ],
   "source": [
    "max_between_day_change = 0\n",
    "for (index, row) in enumerate(data):\n",
    "    if index > 0:\n",
    "      diff = abs(row['Close'] - data[index-1]['Close'])\n",
    "      max_between_day_change = max(diff, max_between_day_change)\n",
    "\n",
    "print('largest change between two consecutive days: ${:2.2f}'.format(max_between_day_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average daily trading volume: $89681.82\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "avg_traded_volume = sum(map(lambda row: row['Traded Volume'], data)) / N\n",
    "\n",
    "print('average daily trading volume: ${:2.2f}'.format(avg_traded_volume))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (Optional) What was the median trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(arr):\n",
    "  sorted_arr = sorted(arr)\n",
    "  if(len(arr) % 2 == 0):\n",
    "    mid_index = len(arr) // 2\n",
    "    return (sorted_arr[mid_index] + sorted_arr[mid_index - 1]) / 2\n",
    "  else:\n",
    "    mid_index = (len(arr) - 1) // 2\n",
    "    return sorted_arr[mid_index]\n",
    "\n",
    "assert median([0,1,2]) == 1\n",
    "assert median([2,1,3]) == 2\n",
    "assert median([0,1,3,4]) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median daily trading volume: $76286.00\n"
     ]
    }
   ],
   "source": [
    "median_traded_volume = median(list(map(lambda row: row['Traded Volume'], data)))\n",
    "print('median daily trading volume: ${:2.2f}'.format(median_traded_volume))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4885f37acae9217c235118400878352aafa7b76e66df698a1f601374f86939a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('springboard': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
